{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea307fae-a39d-46b9-8764-6cdade293c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "from streamlit_webrtc import webrtc_streamer, VideoProcessorBase, RTCConfiguration\n",
    "import av\n",
    "import numpy as np\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import os\n",
    "\n",
    "# =============================\n",
    "# Global Variables & Constants\n",
    "# =============================\n",
    "dot_colors = [\n",
    "    (0, 0, 255),    # Red\n",
    "    (0, 255, 255),  # Yellow\n",
    "    (0, 255, 0),    # Green\n",
    "    (255, 255, 255),# White\n",
    "    (255, 0, 0),    # Blue\n",
    "    (255, 0, 255)   # Purple\n",
    "]\n",
    "color_names = ['Red', 'Yellow', 'Green', 'White', 'Blue', 'Purple']\n",
    "gesture_names = ['Hand_Heart', 'Finger_Heart', 'Middle_Finger', 'Thumbs_Up', 'Thumbs_Down']\n",
    "gesture_friendly_names = {\n",
    "    'Hand_Heart': 'Hand Heart',\n",
    "    'Finger_Heart': 'Finger Heart',\n",
    "    'Middle_Finger': 'Middle Finger',\n",
    "    'Thumbs_Up': 'Thumbs Up',\n",
    "    'Thumbs_Down': 'Thumbs Down'\n",
    "}\n",
    "\n",
    "ANIMATION_PATH_ROOT = os.path.join(os.getcwd(), \"animations\")\n",
    "FRAME_SIZE = (640, 480)\n",
    "\n",
    "# =============================\n",
    "# Helper Functions\n",
    "# =============================\n",
    "def get_animation_path(color_name, gesture_name):\n",
    "    return os.path.join(ANIMATION_PATH_ROOT, f\"{color_name}_{gesture_name}\")\n",
    "\n",
    "def load_animation_frames(color_name, gesture_name, frame_size):\n",
    "    path = get_animation_path(color_name, gesture_name)\n",
    "    if not os.path.exists(path):\n",
    "        return None\n",
    "    files = [f for f in os.listdir(path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    files.sort()\n",
    "    frames = []\n",
    "    for filename in files:\n",
    "        frame_path = os.path.join(path, filename)\n",
    "        frame = cv2.imread(frame_path, cv2.IMREAD_UNCHANGED)\n",
    "        if frame is None:\n",
    "            continue\n",
    "        if frame.shape[2] == 3:\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2BGRA)\n",
    "        frame = cv2.resize(frame, frame_size)\n",
    "        frames.append(frame)\n",
    "    return frames if frames else None\n",
    "\n",
    "# =============================\n",
    "# Gesture Detection Functions\n",
    "# =============================\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "def is_finger_closed(hand_landmarks, finger_tip, finger_pip):\n",
    "    tip = hand_landmarks.landmark[finger_tip]\n",
    "    pip = hand_landmarks.landmark[finger_pip]\n",
    "    return tip.y > pip.y\n",
    "\n",
    "def is_hand_upright(hand_landmarks):\n",
    "    wrist = hand_landmarks.landmark[mp_hands.HandLandmark.WRIST]\n",
    "    mcp = hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_MCP]\n",
    "    return wrist.y > mcp.y\n",
    "\n",
    "def is_heart_gesture(hands_list):\n",
    "    if len(hands_list) != 2:\n",
    "        return False\n",
    "    hand1, hand2 = hands_list\n",
    "    if not (is_hand_upright(hand1) and is_hand_upright(hand2)):\n",
    "        return False\n",
    "    for hand in hands_list:\n",
    "        if not (\n",
    "            is_finger_closed(hand, mp_hands.HandLandmark.MIDDLE_FINGER_TIP, mp_hands.HandLandmark.MIDDLE_FINGER_PIP) and\n",
    "            is_finger_closed(hand, mp_hands.HandLandmark.RING_FINGER_TIP, mp_hands.HandLandmark.RING_FINGER_PIP) and\n",
    "            is_finger_closed(hand, mp_hands.HandLandmark.PINKY_TIP, mp_hands.HandLandmark.PINKY_PIP)\n",
    "        ):\n",
    "            return False\n",
    "    thumb1 = hand1.landmark[mp_hands.HandLandmark.THUMB_TIP]\n",
    "    index1 = hand1.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "    thumb2 = hand2.landmark[mp_hands.HandLandmark.THUMB_TIP]\n",
    "    index2 = hand2.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "    thumb_dist = np.hypot(thumb1.x - thumb2.x, thumb1.y - thumb2.y)\n",
    "    index_dist = np.hypot(index1.x - index2.x, index1.y - index2.y)\n",
    "    return thumb_dist < 0.15 and index_dist < 0.15\n",
    "\n",
    "def is_finger_heart(hand_landmarks):\n",
    "    if not is_hand_upright(hand_landmarks):\n",
    "        return False\n",
    "    if not all(\n",
    "        is_finger_closed(hand_landmarks, tip, pip) for tip, pip in [\n",
    "            (mp_hands.HandLandmark.MIDDLE_FINGER_TIP, mp_hands.HandLandmark.MIDDLE_FINGER_PIP),\n",
    "            (mp_hands.HandLandmark.RING_FINGER_TIP, mp_hands.HandLandmark.RING_FINGER_PIP),\n",
    "            (mp_hands.HandLandmark.PINKY_TIP, mp_hands.HandLandmark.PINKY_PIP)\n",
    "        ]\n",
    "    ):\n",
    "        return False\n",
    "    thumb = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP]\n",
    "    index = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "    distance = np.hypot(thumb.x - index.x, thumb.y - index.y)\n",
    "    return distance < 0.05\n",
    "\n",
    "def is_middle_finger(hand_landmarks):\n",
    "    if not (\n",
    "        is_finger_closed(hand_landmarks, mp_hands.HandLandmark.INDEX_FINGER_TIP, mp_hands.HandLandmark.INDEX_FINGER_PIP) and\n",
    "        is_finger_closed(hand_landmarks, mp_hands.HandLandmark.RING_FINGER_TIP, mp_hands.HandLandmark.RING_FINGER_PIP) and\n",
    "        is_finger_closed(hand_landmarks, mp_hands.HandLandmark.PINKY_TIP, mp_hands.HandLandmark.PINKY_PIP)\n",
    "    ):\n",
    "        return False\n",
    "    middle_tip = hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_TIP]\n",
    "    middle_pip = hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_PIP]\n",
    "    return middle_tip.y < middle_pip.y\n",
    "\n",
    "def is_thumbs_up(hand_landmarks):\n",
    "    wrist = hand_landmarks.landmark[mp_hands.HandLandmark.WRIST]\n",
    "    thumb_tip = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP]\n",
    "    thumb_ip = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_IP]\n",
    "    thumb_mcp = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_MCP]\n",
    "    thumb_up = (thumb_tip.y < wrist.y - 0.02 and\n",
    "                thumb_tip.y < thumb_ip.y - 0.01 and\n",
    "                thumb_ip.y < thumb_mcp.y + 0.03)\n",
    "    open_fingers = 0\n",
    "    for tip, pip in [\n",
    "        (mp_hands.HandLandmark.INDEX_FINGER_TIP, mp_hands.HandLandmark.INDEX_FINGER_PIP),\n",
    "        (mp_hands.HandLandmark.MIDDLE_FINGER_TIP, mp_hands.HandLandmark.MIDDLE_FINGER_PIP),\n",
    "        (mp_hands.HandLandmark.RING_FINGER_TIP, mp_hands.HandLandmark.RING_FINGER_PIP),\n",
    "        (mp_hands.HandLandmark.PINKY_TIP, mp_hands.HandLandmark.PINKY_PIP)\n",
    "    ]:\n",
    "        tip_y = hand_landmarks.landmark[tip].y\n",
    "        pip_y = hand_landmarks.landmark[pip].y\n",
    "        if tip_y < pip_y - 0.05:\n",
    "            open_fingers += 1\n",
    "    return thumb_up and open_fingers <= 1\n",
    "\n",
    "def is_thumbs_down(hand_landmarks):\n",
    "    wrist = hand_landmarks.landmark[mp_hands.HandLandmark.WRIST]\n",
    "    thumb_tip = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP]\n",
    "    thumb_ip = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_IP]\n",
    "    thumb_mcp = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_MCP]\n",
    "    thumb_down = (thumb_tip.y > wrist.y + 0.02 and\n",
    "                  thumb_tip.y > thumb_ip.y + 0.01 and\n",
    "                  thumb_ip.y > thumb_mcp.y - 0.03)\n",
    "    open_fingers = 0\n",
    "    for tip, pip in [\n",
    "        (mp_hands.HandLandmark.INDEX_FINGER_TIP, mp_hands.HandLandmark.INDEX_FINGER_PIP),\n",
    "        (mp_hands.HandLandmark.MIDDLE_FINGER_TIP, mp_hands.HandLandmark.MIDDLE_FINGER_PIP),\n",
    "        (mp_hands.HandLandmark.RING_FINGER_TIP, mp_hands.HandLandmark.RING_FINGER_PIP),\n",
    "        (mp_hands.HandLandmark.PINKY_TIP, mp_hands.HandLandmark.PINKY_PIP)\n",
    "    ]:\n",
    "        tip_y = hand_landmarks.landmark[tip].y\n",
    "        pip_y = hand_landmarks.landmark[pip].y\n",
    "        if tip_y > pip_y + 0.05:\n",
    "            open_fingers += 1\n",
    "    return thumb_down and open_fingers <= 1\n",
    "\n",
    "# =============================\n",
    "# Streamlit WebRTC Video Processor\n",
    "# =============================\n",
    "class VideoProcessor(VideoProcessorBase):\n",
    "    def __init__(self):\n",
    "        self.frame_size = FRAME_SIZE\n",
    "        self.color_name = \"Red\"\n",
    "        self.gesture_name = \"Hand_Heart\"\n",
    "        self.animations = {}\n",
    "        for gesture in gesture_names:\n",
    "            self.animations[gesture] = load_animation_frames(self.color_name, gesture, self.frame_size)\n",
    "        self.anim_index = 0\n",
    "        self.hands = mp_hands.Hands(\n",
    "            static_image_mode=False,\n",
    "            max_num_hands=2,\n",
    "            min_detection_confidence=0.7,\n",
    "            min_tracking_confidence=0.5\n",
    "        )\n",
    "\n",
    "    def recv(self, frame):\n",
    "        img = frame.to_ndarray(format=\"bgr24\")\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        results = self.hands.process(img_rgb)\n",
    "\n",
    "        detected_gesture = None\n",
    "        if results.multi_hand_landmarks:\n",
    "            if len(results.multi_hand_landmarks) == 2 and is_heart_gesture(results.multi_hand_landmarks):\n",
    "                detected_gesture = \"Hand_Heart\"\n",
    "            elif len(results.multi_hand_landmarks) == 1:\n",
    "                hand = results.multi_hand_landmarks[0]\n",
    "                if is_finger_heart(hand):\n",
    "                    detected_gesture = \"Finger_Heart\"\n",
    "                elif is_middle_finger(hand):\n",
    "                    detected_gesture = \"Middle_Finger\"\n",
    "                elif is_thumbs_up(hand):\n",
    "                    detected_gesture = \"Thumbs_Up\"\n",
    "                elif is_thumbs_down(hand):\n",
    "                    detected_gesture = \"Thumbs_Down\"\n",
    "\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                mp.solutions.drawing_utils.draw_landmarks(\n",
    "                    img, hand_landmarks, mp_hands.HAND_CONNECTIONS\n",
    "                )\n",
    "\n",
    "        # Overlay animation for detected gesture\n",
    "        if detected_gesture and self.animations[detected_gesture]:\n",
    "            frames = self.animations[detected_gesture]\n",
    "            anim = frames[self.anim_index % len(frames)]\n",
    "            alpha_s = anim[:, :, 3] / 255.0\n",
    "            alpha_l = 1.0 - alpha_s\n",
    "            for c in range(3):\n",
    "                img[:, :, c] = (alpha_s * anim[:, :, c] +\n",
    "                                alpha_l * img[:, :, c])\n",
    "            self.anim_index += 1\n",
    "        elif self.animations[self.gesture_name]:\n",
    "            # Default animation overlay (for demo)\n",
    "            anim = self.animations[self.gesture_name][self.anim_index % len(self.animations[self.gesture_name])]\n",
    "            alpha_s = anim[:, :, 3] / 255.0\n",
    "            alpha_l = 1.0 - alpha_s\n",
    "            for c in range(3):\n",
    "                img[:, :, c] = (alpha_s * anim[:, :, c] +\n",
    "                                alpha_l * img[:, :, c])\n",
    "            self.anim_index += 1\n",
    "\n",
    "        return av.VideoFrame.from_ndarray(img, format=\"bgr24\")\n",
    "\n",
    "# =============================\n",
    "# Streamlit UI\n",
    "# =============================\n",
    "st.title(\"Gemoji Gesture Animation Demo\")\n",
    "\n",
    "RTC_CONFIGURATION = RTCConfiguration(\n",
    "    {\"iceServers\": [{\"urls\": [\"stun:stun.l.google.com:19302\"]}]}\n",
    ")\n",
    "\n",
    "webrtc_streamer(\n",
    "    key=\"gemoji-demo\",\n",
    "    video_processor_factory=VideoProcessor,\n",
    "    rtc_configuration=RTC_CONFIGURATION,\n",
    "    media_stream_constraints={\"video\": True, \"audio\": False},\n",
    ")\n",
    "\n",
    "st.info(\"Show your hand gesture to see the animation overlay! (Gesture detection is implemented for demo gestures.)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ecfb60-4e97-4a4a-b75f-cf01b895366d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
